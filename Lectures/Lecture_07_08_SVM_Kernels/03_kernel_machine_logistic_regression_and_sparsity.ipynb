{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training some sparse kernel machines\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# setting random_state to a fixed value will make the output deterministic\n",
    "X, y = make_moons(n_samples=100, noise=0.4, random_state=10)\n",
    "\n",
    "# can be found by grid search e.g. via cross-validation\n",
    "C = 5\n",
    "gamma = 0.3\n",
    "\n",
    "# step size in the mesh for plotting\n",
    "h = 0.05\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features_linear_kernel(XX, X=X):\n",
    "    \"\"\"Linear kernel: K(x, x') = x^T x'\"\"\"\n",
    "    return XX.dot(X.T)\n",
    "\n",
    "def transform_features_rbf(XX, gamma=gamma, X=X):\n",
    "    \"\"\"RBF kernel: K(x, x') = exp(-gamma * ||x - x'||^2)\"\"\"\n",
    "    distances = np.sum((XX[:, np.newaxis] - X) ** 2, axis=-1)\n",
    "    return np.exp(-distances * gamma)\n",
    "\n",
    "X_rbf_manual = transform_features_rbf(X) # Kernel matrix from sample matrix\n",
    "print(f\"RBF design matrix shape: {X_rbf_manual.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "for threshold, ax in zip([0.05, 0.2, 0.5], axes):\n",
    "\n",
    "    # train and plot probability map\n",
    "    clf = LogisticRegression(C=C, penalty=\"l1\", solver=\"saga\", multi_class=\"ovr\", max_iter=10000)\n",
    "    clf.fit(X_rbf_manual, y)\n",
    "\n",
    "    # mark all weights that are significantly different from zero as support vectors\n",
    "    support_vectors = np.abs(clf.coef_) > threshold*(np.max(np.abs(clf.coef_))-np.min(np.abs(clf.coef_))) + np.min(np.abs(clf.coef_))\n",
    "    # for prediction only use the support vectors\n",
    "    X_reduced = np.zeros_like(X)\n",
    "    X_reduced[support_vectors[0]] = X[support_vectors[0]]\n",
    "\n",
    "    Z = clf.predict_proba(transform_features_rbf(XX=np.c_[xx.ravel(), yy.ravel()], X=X_reduced))\n",
    "    Z = Z[:, 0].reshape(xx.shape)\n",
    "    ax[0].pcolor(xx, yy, Z)\n",
    "    ax[0].contour(xx, yy, Z, colors=\"k\", levels=[0.5])\n",
    "    ax[0].set_title(\"RBF kernel logisitic regression L1 regularization\")\n",
    "    ax[0].scatter(\n",
    "        X[support_vectors[0], 0],\n",
    "        X[support_vectors[0], 1],\n",
    "        s=200,\n",
    "        facecolor=\"none\",\n",
    "        edgecolor=\"w\",\n",
    "        label=f\"support vectors ($\\\\alpha$ > {threshold:.2f})\",\n",
    "    )\n",
    "\n",
    "    # train and plot probability map\n",
    "    clf = LogisticRegression(C=C, penalty=\"l2\", solver=\"saga\", multi_class=\"ovr\", max_iter=10000)\n",
    "    clf.fit(X_rbf_manual, y)\n",
    "\n",
    "    # mark all weights that are significantly different from zero as support vectors\n",
    "    support_vectors = np.abs(clf.coef_) > threshold*(np.max(np.abs(clf.coef_))-np.min(np.abs(clf.coef_))) + np.min(np.abs(clf.coef_))\n",
    "    # for prediction only use the support vectors\n",
    "    X_reduced = np.zeros_like(X)\n",
    "    X_reduced[support_vectors[0]] = X[support_vectors[0]]\n",
    "\n",
    "    ZZ = clf.predict_proba(transform_features_rbf(XX=np.c_[xx.ravel(), yy.ravel()]))\n",
    "    ZZ = ZZ[:, 0].reshape(xx.shape)\n",
    "    ax[1].pcolor(xx, yy, ZZ)\n",
    "    ax[1].contour(xx, yy, ZZ, colors=\"k\", levels=[0.5])\n",
    "    ax[1].set_title(\"RBF kernel logisitic regression L2 regularization\")\n",
    "    # mark all weights that are significantly different from zero as support vectors\n",
    "    support_vectors = np.abs(clf.coef_) > threshold*(np.max(np.abs(clf.coef_))-np.min(np.abs(clf.coef_))) + np.min(np.abs(clf.coef_))\n",
    "    ax[1].scatter(\n",
    "        X[support_vectors[0], 0],\n",
    "        X[support_vectors[0], 1],\n",
    "        s=200,\n",
    "        facecolor=\"none\",\n",
    "        edgecolor=\"w\",\n",
    "        label=f\"support vectors ($\\\\alpha$ > {threshold:.2f})\",\n",
    "    )\n",
    "\n",
    "    # train and plot probability map\n",
    "    # SVM cannot predict probabilities directly, but proabaility=True uses the Platt scaling essentially interpreting\n",
    "    # th distance to the decision boundary as a probability\n",
    "    clf = SVC(kernel=\"rbf\", gamma=gamma, C=C, probability=True)\n",
    "    clf.fit(X, y)\n",
    "    ZZZ = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "    ZZZ = ZZZ[:, 0].reshape(xx.shape)\n",
    "    support_vectors = clf.support_vectors_\n",
    "    ax[2].pcolor(xx, yy, ZZZ)\n",
    "    ax[2].contour(xx, yy, ZZZ, colors=\"k\", levels=[0.5])\n",
    "    ax[2].scatter(\n",
    "        support_vectors[:, 0],\n",
    "        support_vectors[:, 1],\n",
    "        s=200,\n",
    "        facecolor=\"none\",\n",
    "        edgecolor=\"w\",\n",
    "        label=\"support vectors\",\n",
    "    )\n",
    "    ax[2].set_title(\"SVM with RBF kernel\")\n",
    "\n",
    "    # plot training samples\n",
    "    for a in ax:\n",
    "        a.scatter(X[y == 0, 0], X[y == 0, 1], color=\"r\", marker=\"^\", s=50, facecolors=\"none\", label=\"class 0\")\n",
    "        a.scatter(X[y == 1, 0], X[y == 1, 1], color=\"b\", marker=\"o\", s=50, facecolors=\"none\", label=\"class 1\")\n",
    "        a.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
