{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Import modules\n",
    "# ==============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ==============================================================================\n",
    "# Load data and select features Split into training and test data\n",
    "# ==============================================================================\n",
    "data = datasets.load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "print(data.feature_names)\n",
    "\n",
    "# Split data into training and test data (70% training, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "# ==============================================================================\n",
    "# Scale features using StandardScaler class in scikit-learn\n",
    "# ==============================================================================\n",
    "\n",
    "# Initialise standard scaler and compute mean and STD from training data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "# Transform (standardise) both X_train and X_test with mean and stddev from\n",
    "# training data\n",
    "X_train_sc = sc.transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "\n",
    "print(\"Mean of X_train_sc:\", np.mean(X_train_sc, axis=0))\n",
    "print(\"Stddev of X_train_sc:\", np.std(X_train_sc, axis=0))\n",
    "\n",
    "# df = pd.DataFrame(X_test_sc, columns=data.feature_names)\n",
    "# df[\"target\"] = y_test\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(20,4))\n",
    "# sns.violinplot(df, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Train Logistic Regression model with different regularisation parameters\n",
    "# ==============================================================================\n",
    "\n",
    "c_range = np.arange(-5, 5, 1.0)\n",
    "accuracy = np.zeros(shape=(2, len(c_range)))\n",
    "weights = []\n",
    "\n",
    "for index, c in enumerate(c_range):\n",
    "    clf = LogisticRegression(\n",
    "        max_iter=100, penalty=\"l2\", solver=\"liblinear\", multi_class=\"auto\", random_state=1, C=10.0**c\n",
    "    )\n",
    "    clf.fit(X_train_sc, y_train)\n",
    "    test_score = clf.score(X_test_sc, y_test)\n",
    "    train_score = clf.score(X_train_sc, y_train)\n",
    "    accuracy[0, index] = test_score\n",
    "    accuracy[1, index] = train_score\n",
    "    print(f\"Accuracy test: {test_score:.2f}\")\n",
    "    print(f\"Accuracy train: {train_score:.2f}\")\n",
    "\n",
    "    weights.append(clf.coef_[0])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n",
    "\n",
    "ax[0].plot(c_range, weights)\n",
    "ax[0].set_xlabel(\"Regularisation parameter $log_{10}$(C)\")\n",
    "ax[0].set_ylabel(\"Weights\")\n",
    "\n",
    "\n",
    "# ax[1].plot(c_range, accuracy[0], label=\"Test\")\n",
    "# ax[1].plot(c_range, accuracy[1], label=\"Train\")\n",
    "# ax[1].set_xlabel(\"Regularisation parameter $log_{10}$(C)\")\n",
    "# ax[1].set_ylabel(\"Accuracy\")\n",
    "# ax[1].legend()\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
